import re
import json
import csv
import time
import random
import logging
from datetime import datetime, timezone
from pathlib import Path
import requests
from bs4 import BeautifulSoup

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# íƒ€ê²Ÿ êµ­ê°€ ì„¤ì • (ìœ ëŸ½ ì£¼ìš”êµ­ í¬í•¨)
TARGETS = [
    {"key":"amazon_us","label":"ğŸ‡ºğŸ‡¸ Amazon US","url":"https://www.amazon.com/gp/new-releases/videogames/20972797011/","currency":"USD","kw":["Crimson Desert"]},
    {"key":"amazon_uk","label":"ğŸ‡¬ğŸ‡§ Amazon UK","url":"https://www.amazon.co.uk/gp/new-releases/videogames/6763102031/","currency":"GBP","kw":["Crimson Desert"]},
    {"key":"amazon_de","label":"ğŸ‡©ğŸ‡ª Amazon DE","url":"https://www.amazon.de/gp/new-releases/videogames/22741549031/","currency":"EUR","kw":["Crimson Desert"]},
    {"key":"amazon_fr","label":"ğŸ‡«ğŸ‡· Amazon FR","url":"https://www.amazon.fr/gp/new-releases/videogames/22713180031/","currency":"EUR","kw":["Crimson Desert"]},
    {"key":"amazon_jp","label":"ğŸ‡¯ğŸ‡µ Amazon JP","url":"https://www.amazon.co.jp/gp/new-releases/videogames/8018155051/","currency":"JPY","kw":["Crimson Desert", "ë¶‰ì€ ì‚¬ë§‰", "ç´…ã®ç ‚æ¼ "]},
    {"key":"amazon_ca","label":"ğŸ‡¨ğŸ‡¦ Amazon CA","url":"https://www.amazon.ca/gp/new-releases/videogames/20995057011/","currency":"CAD","kw":["Crimson Desert"]},
    {"key":"amazon_au","label":"ğŸ‡¦ğŸ‡º Amazon AU","url":"https://www.amazon.com.au/gp/new-releases/videogames/7132145051/","currency":"AUD","kw":["Crimson Desert"]},
]

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"}

def scrape_category(cfg):
    r = {"timestamp": datetime.now(timezone.utc).isoformat(), "store": cfg["key"], "label": cfg["label"], "rank_console": None, "price": None, "currency": cfg["currency"], "error": None}
    try:
        resp = requests.get(cfg["url"], headers=HEADERS, timeout=30)
        if resp.status_code != 200:
            r["error"] = f"HTTP {resp.status_code}"
            return r
        
        soup = BeautifulSoup(resp.text, "html.parser")
        # ì•„ë§ˆì¡´ì˜ ë‹¤ì–‘í•œ ê·¸ë¦¬ë“œ ì•„ì´í…œ íŒ¨í„´ ë§¤ì¹­
        items = soup.select(".zg-grid-general-faceout, .p13n-grid-content, #gridItemRoot")
        
        for idx, item in enumerate(items, 1):
            txt = item.get_text(" ", strip=True)
            if any(k.lower() in txt.lower() for k in cfg["kw"]):
                r["rank_console"] = idx
                p_el = item.select_one(".p13n-sc-price, .a-color-price")
                if p_el: r["price"] = re.sub(r'[^\d.]', '', p_el.get_text())
                break
        
        if not r["rank_console"]:
            r["error"] = "Not in Top 50"
            logger.info(f"[{cfg['key']}] ë¶‰ì€ì‚¬ë§‰ì´ ì•„ì§ ìˆœìœ„ê¶Œì— ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        r["error"] = str(e)
    return r

# (ì¤‘ëµ) save() ë° run() ë¡œì§ì€ ë™ì¼
